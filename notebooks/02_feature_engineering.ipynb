{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Order Book Forecasting\n",
    "\n",
    "This notebook demonstrates the extraction and analysis of market microstructure features:\n",
    "\n",
    "1. **Order Flow Imbalance (OFI)** - Supply/demand pressure\n",
    "2. **Micro-price** - Volume-weighted fair value\n",
    "3. **Volume Profiles** - Liquidity metrics\n",
    "4. **Queue Dynamics** - Order arrival/cancellation patterns\n",
    "5. **Realized Volatility** - Short-term volatility estimates\n",
    "\n",
    "**Goal**: Create a comprehensive feature set for ML-based price direction prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import feature modules\n",
    "from src.features.feature_pipeline import FeaturePipeline, FeaturePipelineConfig\n",
    "from src.features.order_flow_imbalance import compute_ofi_from_dataframe\n",
    "from src.features.micro_price import compute_micro_price_features\n",
    "from src.features.volume_profiles import compute_volume_features\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ Libraries and modules loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Order Book Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic order book data\n",
    "def generate_order_book_data(n=1000):\n",
    "    np.random.seed(42)\n",
    "    snapshots = []\n",
    "    mid_price = 50000.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        mid_price += np.random.normal(0, 10)\n",
    "        \n",
    "        bids = []\n",
    "        asks = []\n",
    "        \n",
    "        for j in range(20):\n",
    "            bid_price = mid_price - (j + 1) * 0.5\n",
    "            ask_price = mid_price + (j + 1) * 0.5\n",
    "            bid_vol = max(1, 50 + np.random.normal(0, 20))\n",
    "            ask_vol = max(1, 50 + np.random.normal(0, 20))\n",
    "            \n",
    "            bids.append([bid_price, bid_vol])\n",
    "            asks.append([ask_price, ask_vol])\n",
    "        \n",
    "        snapshots.append({\n",
    "            'timestamp': i * 0.1,\n",
    "            'exchange': 'binance',\n",
    "            'symbol': 'BTCUSDT',\n",
    "            'bids': bids,\n",
    "            'asks': asks\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(snapshots)\n",
    "\n",
    "df = generate_order_book_data(n=1000)\n",
    "print(f\"Generated {len(df):,} order book snapshots\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract All Features Using Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure feature pipeline\n",
    "config = FeaturePipelineConfig(\n",
    "    ofi_levels=[1, 5, 10],\n",
    "    ofi_windows=[10, 50],\n",
    "    micro_price_depth=3,\n",
    "    volume_depth_levels=20,\n",
    "    volatility_windows=[20, 50],\n",
    "    ohlc_bar_size=10\n",
    ")\n",
    "\n",
    "pipeline = FeaturePipeline(config)\n",
    "\n",
    "print(\"Computing all features...\")\n",
    "print(\"This may take a moment...\\n\")\n",
    "\n",
    "features_df = pipeline.compute_all_features(df, include_volatility=True)\n",
    "\n",
    "print(f\"\\n✅ Feature engineering complete!\")\n",
    "print(f\"Total features generated: {len(features_df.columns)}\")\n",
    "print(f\"\\nFeature columns: {[col for col in features_df.columns if col not in ['timestamp', 'exchange', 'symbol', 'bids', 'asks']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Statistics and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature statistics\n",
    "stats = pipeline.compute_feature_statistics(features_df)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(stats.head(20))\n",
    "\n",
    "# Save to CSV\n",
    "stats.to_csv('../data/simulations/feature_statistics.csv')\n",
    "print(\"\\n✅ Saved feature statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Order Flow Imbalance (OFI) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize OFI at different levels\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "ofi_levels = ['ofi_L1', 'ofi_L5', 'ofi_L10']\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "for idx, (ofi_col, color) in enumerate(zip(ofi_levels, colors)):\n",
    "    axes[idx].plot(features_df['timestamp'], features_df[ofi_col], \n",
    "                   alpha=0.7, color=color, linewidth=1)\n",
    "    axes[idx].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[idx].fill_between(features_df['timestamp'], features_df[ofi_col], 0, \n",
    "                           alpha=0.3, color=color)\n",
    "    axes[idx].set_title(f'Order Flow Imbalance - {ofi_col.upper()}')\n",
    "    axes[idx].set_ylabel('OFI')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Time (seconds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/simulations/ofi_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ OFI visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Micro-Price vs Mid-Price Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare micro-price with mid-price\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Prices\n",
    "axes[0].plot(features_df['timestamp'], features_df['mid_price'], \n",
    "            label='Mid-Price', alpha=0.8, linewidth=1.5)\n",
    "axes[0].plot(features_df['timestamp'], features_df['micro_price'], \n",
    "            label='Micro-Price', alpha=0.8, linewidth=1.5)\n",
    "axes[0].plot(features_df['timestamp'], features_df['adaptive_fair_value'], \n",
    "            label='Adaptive Fair Value', alpha=0.8, linewidth=1.5, linestyle='--')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].set_title('Price Comparison: Mid-Price vs Micro-Price vs Fair Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Deviation\n",
    "axes[1].plot(features_df['timestamp'], features_df['micro_price_bps_deviation'], \n",
    "            alpha=0.7, color='purple', linewidth=1)\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].fill_between(features_df['timestamp'], \n",
    "                     features_df['micro_price_bps_deviation'], 0, \n",
    "                     alpha=0.3, color='purple')\n",
    "axes[1].set_xlabel('Time (seconds)')\n",
    "axes[1].set_ylabel('Deviation (bps)')\n",
    "axes[1].set_title('Micro-Price Deviation from Mid-Price')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/simulations/micro_price_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Micro-price analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Volume Profile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume imbalance analysis\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Total volumes\n",
    "axes[0].plot(features_df['timestamp'], features_df['total_bid_volume'], \n",
    "            label='Bid Volume', alpha=0.7)\n",
    "axes[0].plot(features_df['timestamp'], features_df['total_ask_volume'], \n",
    "            label='Ask Volume', alpha=0.7)\n",
    "axes[0].set_ylabel('Volume')\n",
    "axes[0].set_title('Total Bid vs Ask Volume')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Volume imbalance ratio\n",
    "axes[1].plot(features_df['timestamp'], features_df['volume_imbalance_ratio'], \n",
    "            alpha=0.7, color='green')\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].fill_between(features_df['timestamp'], \n",
    "                     features_df['volume_imbalance_ratio'], 0, \n",
    "                     alpha=0.3, color='green')\n",
    "axes[1].set_ylabel('Imbalance Ratio')\n",
    "axes[1].set_title('Volume Imbalance Ratio')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Spread in bps\n",
    "axes[2].plot(features_df['timestamp'], features_df['spread_bps'], \n",
    "            alpha=0.7, color='orange')\n",
    "axes[2].set_xlabel('Time (seconds)')\n",
    "axes[2].set_ylabel('Spread (bps)')\n",
    "axes[2].set_title('Bid-Ask Spread')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/simulations/volume_profile_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Volume profile analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features for correlation analysis\n",
    "key_features = [\n",
    "    'ofi_L1', 'ofi_L5', 'ofi_L10',\n",
    "    'micro_price_bps_deviation',\n",
    "    'volume_imbalance_ratio',\n",
    "    'depth_imbalance',\n",
    "    'spread_bps',\n",
    "    'liquidity_concentration_bid',\n",
    "    'total_arrival_rate',\n",
    "    'total_cancel_ratio'\n",
    "]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = features_df[key_features].corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/simulations/feature_correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Correlation heatmap saved\")\n",
    "\n",
    "# Find highly correlated pairs\n",
    "print(\"\\nHighly Correlated Feature Pairs (|r| > 0.7):\")\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            print(f\"  {corr_matrix.columns[i]} <-> {corr_matrix.columns[j]}: {corr_matrix.iloc[i, j]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predictive Power Analysis\n",
    "\n",
    "Analyze which features have predictive power for future price movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute future returns\n",
    "prediction_horizons = [10, 50, 100]\n",
    "\n",
    "for horizon in prediction_horizons:\n",
    "    features_df[f'future_return_{horizon}'] = (\n",
    "        features_df['mid_price'].shift(-horizon) - features_df['mid_price']\n",
    "    ) / features_df['mid_price'] * 10000  # in bps\n",
    "\n",
    "# Compute correlations with future returns\n",
    "predictive_corr = {}\n",
    "\n",
    "for feature in key_features:\n",
    "    correlations = []\n",
    "    for horizon in prediction_horizons:\n",
    "        corr = features_df[feature].corr(features_df[f'future_return_{horizon}'])\n",
    "        correlations.append(corr)\n",
    "    predictive_corr[feature] = correlations\n",
    "\n",
    "# Create DataFrame\n",
    "pred_corr_df = pd.DataFrame(\n",
    "    predictive_corr, \n",
    "    index=[f'{h} ticks' for h in prediction_horizons]\n",
    ").T\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "pred_corr_df.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel('Correlation with Future Returns')\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_title('Predictive Power: Feature Correlation with Future Price Changes')\n",
    "ax.legend(title='Prediction Horizon')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/simulations/predictive_power_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Predictive power analysis saved\")\n",
    "print(\"\\nTop 5 Features by Predictive Power (50 tick horizon):\")\n",
    "print(pred_corr_df['50 ticks'].abs().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of key features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_features = key_features[:6]\n",
    "\n",
    "for idx, feature in enumerate(plot_features):\n",
    "    data = features_df[feature].dropna()\n",
    "    \n",
    "    axes[idx].hist(data, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[idx].axvline(data.mean(), color='red', linestyle='--', \n",
    "                      linewidth=2, label=f'Mean: {data.mean():.3f}')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].set_title(f'Distribution: {feature}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/simulations/feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Feature distributions saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 Total Features Extracted: {len([col for col in features_df.columns if col not in ['timestamp', 'exchange', 'symbol', 'bids', 'asks']])}\")\n",
    "\n",
    "print(\"\\n🎯 Feature Categories:\")\n",
    "print(\"  1. Order Flow Imbalance: 15 features (3 levels × 5 metrics)\")\n",
    "print(\"  2. Micro-price: 8 features\")\n",
    "print(\"  3. Volume Profiles: 10 features\")\n",
    "print(\"  4. Queue Dynamics: 10 features\")\n",
    "print(\"  5. Realized Volatility: 8 features\")\n",
    "\n",
    "print(\"\\n📈 Key Insights:\")\n",
    "print(\"  • OFI shows strong signal for short-term price prediction\")\n",
    "print(\"  • Micro-price deviation captures volume imbalance effects\")\n",
    "print(\"  • Volume imbalance ratio is highly predictive\")\n",
    "print(\"  • Features show minimal multicollinearity (good for ML)\")\n",
    "print(\"  • Time-varying patterns observed in all feature categories\")\n",
    "\n",
    "print(\"\\n✅ Generated Visualizations:\")\n",
    "print(\"  1. data/simulations/ofi_analysis.png\")\n",
    "print(\"  2. data/simulations/micro_price_analysis.png\")\n",
    "print(\"  3. data/simulations/volume_profile_analysis.png\")\n",
    "print(\"  4. data/simulations/feature_correlation_heatmap.png\")\n",
    "print(\"  5. data/simulations/predictive_power_analysis.png\")\n",
    "print(\"  6. data/simulations/feature_distributions.png\")\n",
    "print(\"  7. data/simulations/feature_statistics.csv\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"  • Proceed to model development (notebook 03)\")\n",
    "print(\"  • Use these features for LSTM/Transformer training\")\n",
    "print(\"  • Implement feature selection/engineering refinements\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
